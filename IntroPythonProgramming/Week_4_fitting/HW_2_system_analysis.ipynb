{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"HW_2_system_analysis.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2: Analysis of a mass-damped system\n",
    "\n",
    "Resources: Lecture slides describing the homework: https://docs.google.com/presentation/d/1MwF34w30rjzLS5-IYj0ZWT5CjsLeFc7qlG_Eq9rFdZ8/edit?usp=sharing All of the equations for this homework are in those slides.\n",
    "\n",
    "- Part 1/week 4 does not build on anything specific in lab 4, but uses functions and numpy\n",
    "- Part 2/week 5: Do lab 5 before homework \n",
    "\n",
    "In the first part of this homework the focus is on doing an analysis \"from scratch\", in the sense that we will not be\n",
    "providing a lot of shell code. The second half is on how to translate a general equation of the form\n",
    "\n",
    "  *derivative of state at time t = f( state at time t )*\n",
    "  \n",
    "into code (also known as simulation).\n",
    "\n",
    "Programming practice: The focus in this assignment is on deciding when to create a function and what parameters to pass in and out of the function.\n",
    "\n",
    "Following on from lab 5, the second part of the assignment will be an example of writing an iterative function - one where the intention is to call the function multiple times, each time passing in the values returned from the previous function call. This can be a bit difficult to wrap your head around, so if you get stuck go back to the simpler examples and/or do it on paper yourself a few iterations.\n",
    "\n",
    "We've provided results (as a json file) for three of the included data sets. We will, however, be testing on different data sets, so make sure your code works for any data file of the correct format.\n",
    "\n",
    "TODOS: For each helper function\n",
    "- Write the function\n",
    "- Check that it works\n",
    "\n",
    "You have some flexibility as to how the write the helper functions, but you must use the names/input/output format given or the autograder won't work...\n",
    "\n",
    "Helper function is not a technical term - it's just what I call a function that does some part of the functionality of the entire task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Helper function 1 - load the data and check that it's valid\n",
    " - Input: File name (with path)\n",
    " - Output: Two numpy arrays\n",
    "   -- 1st numpy array: The time values\n",
    "   -- 2nd numpy array: The function values that correspond to the time values\n",
    "   \n",
    "You MUST use this format and the file name given, or the autograder will fail.\n",
    "\n",
    "The two arrays should be of the same length\n",
    "\n",
    "Some expectations on the data files\n",
    " - Always has at least three rows\n",
    " --First row is a header row\n",
    "- The first column is the time values (will be monotonically increasing)\n",
    "- The second column is the values that correspond to the time values (final value of this will be greater than initial)\n",
    "\n",
    "A good habit is to check that these are true, and throw an error if it's not\n",
    "\n",
    "Note: Use numpy's **loadtxt** to load the data. **loadtxt** has an option to skip rows, so that you can skip the headers at the front of the row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Put your imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Put your function definition for loading the data here\n",
    "# Note: use the variable viewer to check that the ts and vs are correct/the same as in the .csv file\n",
    "#  Reminder: usie numpy's loadtxt - you just have to tell it to skip the first row\n",
    "\n",
    "# You must name your function load_data_from_file with the first parameter being the filename\n",
    "#  The function should return ts, vs\n",
    "def load_data_from_file(fname):\n",
    "    t_values = ...\n",
    "    y_values = ...\n",
    "    return t_values, y_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Call your function here\n",
    "\n",
    "# Make sure that you assign the t and y values to the variable names ts_data1, vs_data1\n",
    "# Read data in from data1.csv\n",
    "ts_data1, vs_data1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"load_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Helper function 2 - get the index of the local minima or local maxima\n",
    "\n",
    "Look at the equations in the slides - why is this a useful helper function?\n",
    "\n",
    "- Input (2): A numpy array, boolean (True: find local maxima, False: find local minima)\n",
    "- Output: The index of every local maxima or local minima in the input array\n",
    "\n",
    "Use the **argrelmin** and **argrelmax** functions to find the indices of the minimum and maximum values in a numpy array.\n",
    "These functions are in scipy.signal module. They essentially bundle the find max, and where code we've been writing\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.argrelmin.html\n",
    "- https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.argrelmax.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: Add importing argrelmax and argrelmin to your imports. They are in scipy.signal\n",
    " \n",
    "# TODO: Write b_peak_or_valley function.\n",
    "# This function takes in data and whether or not to search for the peak or the valley. It returns an index or None if no peak/valley\n",
    "# If b_peak_or_valley is True, return the peak\n",
    "def find_peak_or_valley(data, b_peak_or_valley):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test your function with datas.\n",
    "data_a = np.array([1.0, 3.0, 4.0, 7.0, 6.0, 8.0, 9.0, 10.0, 5.0])\n",
    "data_b = np.array([-2.5, 1.0, 4.0, 8.0, 4.0, 1.0, -2.5])\n",
    "data_c = np.array([1.1, 2.2, 3.3, 4.4])\n",
    "\n",
    "# TODO Add tests - what should the correct values be? If you are unsure, try plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"get_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Analysis code\n",
    "\n",
    "TODO: Write a function that takes in a file name and outputs a dictionary with the values listed below\n",
    " - You must use the names given (see json file/example in homework slide)\n",
    " - See homework slides for further definitions/equations\n",
    "\n",
    "Check the corresponding json file and plot for the correct values \n",
    "\n",
    "### System values (Slide 8)\n",
    " - c_initial - the initial position of the system (the first value)\n",
    " - c_peak - the largest position of the system (or the first peak position, see Figure 4.14)\n",
    " - c_final - the final, steady-state position of the system (the last value, see Figure 4.14)\n",
    "\n",
    "Note: For this assignment we'll just use the last value, but you could also average the last few values\n",
    "\n",
    "###  Estimate peak and valley times and values\n",
    " - c_second_peak - the second peak position of the system (local maximum value)\n",
    " - c_valley - the first valley position of the system (local minimum value)\n",
    " - t_peak - the peak time of the system\n",
    " - t_second_peak - the second peak time of the system\n",
    " - t_valley - the first valley time of the system\n",
    " - peak_period - the period between two peaks, (t_second_peak - t_peak) or (t_valley - t_peak)*2\n",
    " - perc_overshoot - percentage over shoot (% OS). This is the amount that the system overshoots c_final, expressed as a percentage of the range c_initial to c_final.\n",
    "\n",
    "###    Estimate model values\n",
    " - system_mass - assume the mass is 1 (this will not be true in part II)\n",
    " - system_spring - this is omega_n^2 * system_mass (see slides)\n",
    " - system_damping - the damping coeifficient (the linear coefficient, see slides)\n",
    "\n",
    "You may write some additional helper functions here, if you wish. Actually, I recommend writing this in pieces/multiple functions. One breakdown is the one given above - calculate the values in turn.\n",
    "\n",
    "I'd suggest writing a test function for each of the group of equations above, where you test against the answers in the data1.json file (with the data1.csv file as input). \n",
    "\n",
    "I have written a general-purpose test function for you, but it tests everything all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell for the first function (you write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test cell for that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  Another cell for a second function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another cell for testing the above function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Another cell for another function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: Based on the given ts and vs, create a dictionary with all of the parameters. Return the dictionary.\n",
    "# If mass is not given, assume it is 1\n",
    "def analyze_data_from_values(ts, vs, mass=1.0):\n",
    "    pass    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: Open the filename and call the analyze_data_from_values function. Return the dictionary.\n",
    "# If mass is not given, assume it is 1\n",
    "def analyze_data(fname, mass=1.0):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "\n",
    "# Call the analyze_data function(s) with one of the data files \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_dictionaries(fname_dictionary, check_dict):\n",
    "    \"\"\" Open up the json file in fname and compare to check_dict\n",
    "    @param fname_dictionary one of dataX.json\n",
    "    @param check_dict - your dictionary with parameters\n",
    "    @returns True or False if the same (within epsilon)\"\"\"\n",
    "    from json import load\n",
    "    with open(fname_dictionary, 'r') as fp:\n",
    "        answ_dict = load(fp)\n",
    "\n",
    "    b_ret = True\n",
    "    for k, v in answ_dict.items():\n",
    "        try:\n",
    "            if not np.isclose(v, check_dict[k], rtol=0.1):\n",
    "                print(f\"Key {k} is not close, correct value {v}, incorrect {check_dict[k]}\")\n",
    "                b_ret = False\n",
    "        except KeyError:\n",
    "            print(f\"Key {k} not found in your dictionary\")\n",
    "            b_ret = False\n",
    "    return b_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Plot the data and the system parameters\n",
    "\n",
    "TODO Plot the data with the parameters, similar to the figures in the slides\n",
    "\n",
    "You should have **the first and second peaks**, **the first valley**, and **peak period** plotted on the figure\n",
    "\n",
    "Optional: Plot all of the data on the left hand side, then plot a \"clipped\" version of the data (clip to where it stops vibrating) with the parameters on them.\n",
    "\n",
    "Create one plot each for each data file.\n",
    "\n",
    "- matplotlib has a text function for placing text\n",
    "\n",
    "When deciding what functions to write: I've left four blocks here. The first block should be function(s) that do the plotting/reading/analysis, etc. Blocks 2-4 should just call those functions with the different data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An example of creating a \"helper\" function that does a plotting task \n",
    "def draw_corner(axs, x_values, y_values, ls, col):\n",
    "    axs.plot([x_values[0], x_values[1]], [y_values[1], y_values[1]], linestyle=ls, color=col)\n",
    "    axs.plot([x_values[1], x_values[1]], [y_values[0], y_values[1]], linestyle=ls, color=col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell for writing additional plot functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "    \n",
    "# TODO: \n",
    "#  Write a function, plot_system, that reads in the data, analyzes it, then plots it\n",
    "def plot_system(axs, fname, m=1.0):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(12, 3))\n",
    "\n",
    "# Read, analyze, and then plot data 1\n",
    "\n",
    "# Make it fit better\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(12, 3))\n",
    "\n",
    "# Read, analyze, and then plot data 2\n",
    "\n",
    "# Make it fit better\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(12, 3))\n",
    "\n",
    "# Read, analyze, and then plot data 3\n",
    "\n",
    "# Make it fit better\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual grade\n",
    "print(\"This is a manually-graded question; there is no grader.check() function. See rubric and slides for more information on expected output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Part 2 - ode simulation\n",
    "\n",
    "In this part of the assignment you'll simulate the spring-mass system yourself. We'll follow the second half of Lab 5 - using ode to do the simulation (you just have to write the derivative function and the set-up code).\n",
    "\n",
    "This should be nearly identical to the predator_prey_derivative ode example (from a coding syntax standpoint). The equations and the meanings of the variables will be different, however.\n",
    "\n",
    "- Like the c_tutorial_iterative_systems example, you will need to calculate two values, but this time dx/dt and dx^2/dt^2 \n",
    "- Like the predator_prey_derivative example, you will\n",
    "-- create a derivative function that takes in a 2 dimensional current state (x, dx/dt), t (not used), and params (c, k, and m) and returns dx/dt and dx^2/d^2t\n",
    "-- params will be a dictionary that you create in the calling code\n",
    "-- create a set of time values to evaluate the system at\n",
    "-- use ode to do the actual forward simulation\n",
    "\n",
    "Functions you'll need\n",
    "\n",
    "- a derivative function (like predator_prey_derivative)\n",
    "- a function/cell to create the initial data to simulate and write out/save the results\n",
    "- a function that calls your code from part 1 to analyze and plot the data (do NOT write new plotting/analysis code). Two options:\n",
    "-- Write the data out to a file then read it back in using the code you just wrote in the previous part\n",
    "-- If you split up your plot/analysis functions the right way, you can just pass the data directly to the plot/analysis functions\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- c: damping term (system_damping in json file)\n",
    "- k: spring term (system_spring in json file)\n",
    "- m: mass (don't forget to put this value in the analysis dictionary)\n",
    "\n",
    "Equation:\n",
    "\n",
    "-  dx/dt = dx/dt\n",
    "-  d^2x/d^2t = (-c * dx/dt - k * x) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: You'll need to import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: write a deriative function.\n",
    "#  Note that the input state will have x and the derivative of x in it\n",
    "#   You will return the derivative of x and the derivative of the derivative of x\n",
    "#   Note that the derivative never changes - you only have to calculate the second derivative\n",
    "# This is the function that you will pass to odeint \n",
    "# It should implememt the Equations for dx/dt and d^2x/d^2t given above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "# Write a call to the derivative function to test it with known values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO write a function that takes in the starting conditions (x and the derivative of x), along with the parameters\n",
    "#  you need to calculate the derivative (zeta, k, and m)\n",
    "# Call integrate.odeint with the function you created above, plus your parameters, \n",
    "#  and return the result of that function, along with the t values\n",
    "#   You might also want pass in the step for the t and the total amount of time to integrate over as parameters\n",
    "# \n",
    "# This function should setup the initial state, figure out which set of t value (ts) you want,\n",
    "#   and pass the parameters in to integrate.odeint. \n",
    "# It should return the t values you created and the values (just the position, not the first derivative)\n",
    "# In otherwords, ts and vs just like you read in from the dataX.csv files\n",
    "#\n",
    "# A note on the t values: these can be relatively sparse (60-100 per period); odeint will adjust its sampling rate in order to\n",
    "#   make sure the values are close to correct at the t values you give it. If you give it lots of t values, it will take longer\n",
    "#   to run (and to plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this cell you'll take the ts and vs you just calculated with odeint and pass them to\n",
    "#   your analyze_data function to get out the peaks/period\n",
    "\n",
    "# Run the ode with the following parameters and store the answer in dict_answ\n",
    "# Make sure you run the simulation long enough for it to stabilize\n",
    "# x0 = -0.5, c = 1.1, m = 2.0, k = 50.0\n",
    "dict_answ_ode1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"ode_functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "# Part b: Recreate data 1\n",
    "Using your simulation code, re-create the plot for data 1\n",
    "\n",
    "- Get the parameters from your initial analysis\n",
    "- Pick a reasonable stop time\n",
    "- Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(8, 4))\n",
    "\n",
    "# Run your simulation, analyze it, and plot the results\n",
    "# Note: This SHOULD just be calling existing functions\n",
    "# Paraneters you should use for the simulate are the starting conditions for data1\n",
    "#    k is system_spring, c is system_damping\n",
    "# x0 = -1.0, c = 1.0, m = 1.0, k = 100.0\n",
    "# Simulate\n",
    "#  - gets ts and vs\n",
    "# Analayze\n",
    "#  - gets dictionary from ts and vs\n",
    "#  - use that data in your plot to plot the first/second peaks etc\n",
    "# Plot\n",
    "#  - plot the ts and vs with the peaks etc labeled (same as in part 1)\n",
    "\n",
    "# Make it fit better\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Manual grade\n",
    "print(\"This is a manually-graded question; there is no grader.check() function. See rubric and slides for more information on expected output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Part c - increasing mass\n",
    "\n",
    "Increase the mass from 1 to 10 (but use the same c and k parameters from the previous problem).\n",
    "\n",
    "Plot the system. Has it stabilized? Adjust the time to run so that it stabilizes. Then plot the result.\n",
    "\n",
    "Set dict_bigger_analysis to be the analysis with mass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nrows = 1\n",
    "ncols = 2\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(8, 4))\n",
    "\n",
    "\n",
    "# Run and plot the simulation with the mass increased to 10.\n",
    "# Other parameters are the same as in the part b.\n",
    "dict_bigger_mass_analysis = ...\n",
    "\n",
    "# Make it fit better\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your analysis (set dict_bigger_mass_analysis)\n",
    "assert(compare_dictionaries('Data/sim_and_plot_answer_c.json', dict_bigger_mass_analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"bigger_mass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"not filled out\"}\n",
    "# List of URLS I25 (creates a set)\n",
    "websites = {\"not filled out\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit\n",
    "\n",
    "- Make sure you have comments for your functions and in your code\n",
    "- Do a restart then run all to make sure everything runs ok. DO THIS. \n",
    "- Take out print statements that result in pages of numbers\n",
    "- Save the file\n",
    "- Submit just this .ipynb file through gradescope, HW 2 system analysis\n",
    "- You do NOT need to submit the data files - we will supply those\n",
    "- Where there are given variable/file names (eg, foo = ...) DON'T change those, or the autograder will fail\n",
    "\n",
    "If the Gradescope autograder fails, please check here first for common reasons for it to fail\n",
    "    https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing\n",
    "\n",
    "Most likely failure for this assignment is not naming the data directory and files correctly and/or reading and writing files to other directories.\n",
    "\n",
    "A second gentle reminder that you should NOT be copying and pasting code (let alone sending files) to other people in the class. We do run all of the code through a plagiarism detector. Including previous terms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "analysis": {
     "name": "analysis",
     "points": 9,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert compare_dictionaries('Data/data1.json', analyze_data('Data/data1.csv'))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert compare_dictionaries('Data/data2.json', analyze_data('Data/data2.csv'))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert compare_dictionaries('Data/data3.json', analyze_data('Data/data3.csv'))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "bigger_mass": {
     "name": "bigger_mass",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(dict_bigger_mass_analysis['system_spring'], 100.0, atol=1.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_bigger_mass_analysis['system_damping'], 1.0, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_bigger_mass_analysis['system_mass'], 10.0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "get_index": {
     "name": "get_index",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert all(find_peak_or_valley(data_a, b_peak_or_valley=True) == [3, 7])\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all(find_peak_or_valley(data_a, b_peak_or_valley=False) == 4)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert all(find_peak_or_valley(data_b, b_peak_or_valley=True) == 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(find_peak_or_valley(data_b, b_peak_or_valley=False)) == 0\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(find_peak_or_valley(data_c, True)) == 0\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(find_peak_or_valley(data_c, False)) == 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not 'not filled out' in worked_with_names\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not 'not filled out' in websites\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert hours > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "load_data": {
     "name": "load_data",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(ts_data1) == len(vs_data1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert len(ts_data1) == 20000\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert vs_data1[-1] > vs_data1[0]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "ode_functions": {
     "name": "ode_functions",
     "points": 6,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['c_initial'], -0.5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['c_peak'], 0.4205476, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['c_final'], -0.0015, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['c_second_peak'], 0.297513, atol=0.01)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['c_valley'], -0.35372027869507117, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['t_peak'], 0.629, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['t_second_peak'], 1.888, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['t_valley'], 1.259, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['t_valley'], 1.259, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['peak_period'], 1.26, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['perc_overshoot'], 83.45145562088324, atol=0.1)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['system_mass'], 2.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['system_spring'], 50, atol=0.5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_answ_ode1['system_damping'], 1.1, atol=0.1)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
