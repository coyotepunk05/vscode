{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Lab_2_functions.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Statistical analysis of data using numpy\n",
    "\n",
    "Lab slides: (https://docs.google.com/presentation/d/1ykwwcQ0onMvAjUxfJmKl9tbo-rJPdB5pRwDEmpDsd-g/edit?usp=sharing)\n",
    "\n",
    "For this lab the goal is to write functions to pull out one data channel and print out statistics for different types of hand motions. We will write a function to load data from a single file, a second to combine data from multiple files, a third to pull out the data for a selected data channel, then a fourth to calculate statistics.\n",
    "\n",
    "Written properly, you only need one function to do stats for the entire data channel or for just one type of hand motion. For any data channel. In the homework you'll use this logic to apply statistics to a specific data channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "import numpy as np\n",
    "import json as json\n",
    "# os is needed for calling os.path.basename\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Reading in data\n",
    "\n",
    "Based on your code from Lab 1, write a function `get_data` that loads the data from a single CSV and adds a column at the end containing the hand motion ID. Then, write a function `get_data_from_files` that loads data from a list of CSV files into a single numpy array using `get_data`.\n",
    "\n",
    "Both functions will operate on a dictionary containing `\"csv_path\"` which holds the path to the data file and `\"motion_id\"` which holds the ID of the motion contained within the CSV file. You will write a third function `get_file_info` that returns this dictionary for a given CSV file, which will extract the motion type from the file name.\n",
    "\n",
    "Note: The functions initially just contain `pass`, which is just a placeholder that you should remove. In Python, `pass` does nothing at all by design, but removing it and having an empty function is illegal ([docs](https://docs.python.org/3/tutorial/controlflow.html#pass-statements))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Numeric ids to indicate hand motion type from Lab 1\n",
    "clap_id = 1\n",
    "high_five_id = 2\n",
    "snap_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(file_info):\n",
    "    \"\"\" Function that returns the data from the given CSV file.\n",
    "    @param file_info - a dictionary with keys \"csv_path\" and \"motion_id\"\n",
    "    @return Return array should contain data in file with an extra column at the end containing the motion_id.\"\"\"\n",
    "\n",
    "    # import csv as file_data\n",
    "    file_data = np.loadtxt(file_info[\"csv_path\"], dtype=\"float\", delimiter=\",\")\n",
    "\n",
    "    # get motion id\n",
    "    motion_id = file_info[\"motion_id\"]\n",
    "\n",
    "    # create numpy array, add file_data and append motion_id\n",
    "    file_data_motion = np.zeros((file_data.shape[0], file_data.shape[1]+1))\n",
    "    file_data_motion[:, 0:-1] = file_data\n",
    "    file_data_motion[:, -1] = motion_id\n",
    "\n",
    "    return file_data_motion\n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_from_files(file_list):\n",
    "    \"\"\" Function that returns data from a list of files.\n",
    "    @param file_list - a list of dictionaries, where each dictionary contains `csv_path` and `motion_id`.\n",
    "    @return A single return array containing the data from all of the given input files.\"\"\"\n",
    "\n",
    "    # create empty list :)\n",
    "    file_list_list = []\n",
    "\n",
    "    # based on input list run previous function, concatinate\n",
    "    for item in file_list:\n",
    "\n",
    "        data = get_data(item)\n",
    "        file_list_list.append(data)\n",
    "\n",
    "    return np.concatenate(file_list_list)\n",
    "\n",
    "\n",
    "    # Hint: Use np.concatenate to combine multiple numpy arrays.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "# SCRATCH cell\n",
    "fname_chop_up = \"Data/S01C01.csv\"\n",
    "res = os.path.basename(fname_chop_up)\n",
    "\n",
    "# TODO.. look at res. How would you get out the C F or S character?\n",
    "res_letter = res[3]\n",
    "print(res_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_path': 'Data/S01C01.csv', 'motion_id': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint: Use `os.path.basename` to get the filename of the CSV file (e.g., S10F01.csv),\n",
    "# extract the C/F/S character which will appear at a fixed offset in the filename,\n",
    "# and then return the right motion ID based on that character. Remember that C is a\n",
    "# clap, F is a high five, and S is a snap.\n",
    "def get_file_info(csv_path):\n",
    "    \"\"\"Function that returns a file_info dictionary for a given filepath.\n",
    "    @param csv_path - path to a CSV file containing a hand motion\n",
    "    @return A dictionary with key \"csv_path\", containing csv_path, and \"motion_id\", containing the type of motion encoded in the file.\"\"\"\n",
    "\n",
    "    # get file name from path and find 4th letter\n",
    "    filename = os.path.basename(csv_path)\n",
    "    data_letter = filename[3]\n",
    "\n",
    "    # determine motion_id based on 4th letter\n",
    "    if data_letter == \"C\":\n",
    "        motion_id = clap_id\n",
    "    elif data_letter == \"F\":\n",
    "        motion_id = high_five_id\n",
    "    elif data_letter == \"S\":\n",
    "        motion_id = snap_id\n",
    "\n",
    "    # create dictionary based on path and motion_id\n",
    "    data_info = {\"csv_path\":csv_path, \"motion_id\":motion_id}\n",
    "\n",
    "    return data_info\n",
    "\n",
    "    # data_letter = filename\n",
    "\n",
    "    # The base file path is of the form S##[C|F|S]##.csv.\n",
    "    pass\n",
    "\n",
    "get_file_info(\"Data/S01C01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in data from the files in lab 1 using the functions you just wrote.\n",
    "all_data = get_data_from_files([\n",
    "    get_file_info(\"Data/S01C01.csv\"),\n",
    "    get_file_info(\"Data/S01F01.csv\"),\n",
    "    get_file_info(\"Data/S01S01.csv\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>get_data</pre></strong> passed! ðŸ’¯</p>"
      ],
      "text/plain": [
       "get_data results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"get_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Doing the slice\n",
    "\n",
    "Get the data for one of the channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# This reads in the json data\n",
    "\n",
    "# import data description dictionary\n",
    "try:\n",
    "    with open(\"Data/data_description.json\", \"r\") as fp:\n",
    "        data_description = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file was not found; check that the data directory is in the current one and the file is in that directory\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_descriptor(data_description, name):\n",
    "    \"\"\" Returns the descriptor for the given data channel.\n",
    "    @param name - The name of the data channel to look for. \"\"\"\n",
    "\n",
    "# check if item in data description is desired\n",
    "    for item in data_description[\"data_channels\"]:\n",
    "        if item[\"name\"] == name:\n",
    "            descriptor_dict = item\n",
    "            break\n",
    "\n",
    "    return descriptor_dict\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_channel_data(all_data, index_offset, n_dims):\n",
    "    \"\"\" Get the data for just one channel (e.g., right hand accelerometer)\n",
    "    @param all_data - numpy array containing data from one or more files\n",
    "    @param index_offset - the column to begin getting data from\n",
    "    @param n_dims - number of dimensions for the data channel\n",
    "    @return Return array should be number of rows in all_data X n_dims\"\"\"\n",
    "\n",
    "    # create array with shape of data and desired dimensions\n",
    "    channel_data = np.zeros((all_data.shape[0], n_dims))\n",
    "    # insert desired data into array\n",
    "    channel_data = all_data[:, index_offset:index_offset + n_dims]\n",
    "\n",
    "    return channel_data\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test 1 - the right hand accelerometer data\n",
    "rh_accelerometer_descriptor = get_descriptor(data_description, \"Right hand accelerometer\")\n",
    "rh_accelerometer_data = get_channel_data(all_data, index_offset=rh_accelerometer_descriptor[\"index_offset\"], n_dims=rh_accelerometer_descriptor[\"dimensions\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of rhs_accelerometer_data is (285, 3), should be 285 X 3\n",
      "First row, first column value 0.70, should be 0.70\n",
      "First row, last column value -0.41, should be -0.41\n",
      "Last row, first column value 0.07, should be 0.07\n",
      "Last row, last column value -0.98, should be -0.98\n"
     ]
    }
   ],
   "source": [
    "# SELF TESTS\n",
    "print(f\"Shape of rhs_accelerometer_data is {rh_accelerometer_data.shape}, should be 285 X 3\")\n",
    "print(f\"First row, first column value {rh_accelerometer_data[0, 0]:0.2f}, should be 0.70\")\n",
    "print(f\"First row, last column value {rh_accelerometer_data[0, -1]:0.2f}, should be -0.41\")\n",
    "print(f\"Last row, first column value {rh_accelerometer_data[-1, 0]:0.2f}, should be 0.07\")\n",
    "print(f\"Last row, last column value {rh_accelerometer_data[-1, -1]:0.2f}, should be -0.98\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests for Left hand gyroscope\n",
    "lh_gyroscope_descriptor = get_descriptor(data_description, \"Left hand gyroscope\")\n",
    "lh_gyroscope_data = get_channel_data(all_data, index_offset=lh_gyroscope_descriptor[\"index_offset\"], n_dims=lh_gyroscope_descriptor[\"dimensions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check size and first, last element\n",
    "\n",
    "assert(lh_gyroscope_data.shape == (all_data.shape[0], 3))\n",
    "assert(np.isclose(lh_gyroscope_data[0, 0], 429.34))\n",
    "assert(np.isclose(lh_gyroscope_data[-1, -1], -154.36))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>check_slice</pre></strong> passed! ðŸŒˆ</p>"
      ],
      "text/plain": [
       "check_slice results: All test cases passed!"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"check_slice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Compute stats: Write a function to calculate the four stats\n",
    "\n",
    "This is a variation on what you did in lab 1; in this case, we're going to do it with two functions. The first calculates the stats and returns the dictionary (**calc_stats**) the second does the **for** loop to make one dictionary for each dimension in the data.\n",
    "\n",
    "- Step 1 [this problem] - do the **calc_stats** function\n",
    "- Step 2 [next problem] - do the loop to calculate the stats for each x,y,z channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stats(data):\n",
    "    \"\"\"Calculate min, max, mean and standard deviation for the array and put in a dictionary\n",
    "    @param data a numpy array\n",
    "    @return a dictionary\"\"\"\n",
    "\n",
    "    # Use keys Min, Max, Mean, and SD\n",
    "\n",
    "    # create dictionary to insert stats into\n",
    "    stats_dict = {\"Min\":0, \"Max\":0, \"Mean\":0, \"SD\":0}\n",
    "\n",
    "    # find stats\n",
    "    stats_dict[\"Min\"] = np.min(data)\n",
    "    stats_dict[\"Max\"] = np.max(data)\n",
    "    stats_dict[\"Mean\"] = np.mean(data)\n",
    "    stats_dict[\"SD\"] = np.std(data)\n",
    "\n",
    "    return stats_dict\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function with known data\n",
    "test_data = np.linspace(0, 1, 10)\n",
    "ret_dict = calc_stats(test_data)\n",
    "\n",
    "assert(np.isclose(ret_dict[\"Min\"], 0.0))\n",
    "assert(np.isclose(ret_dict[\"Max\"], 1.0))\n",
    "assert(np.isclose(ret_dict[\"Mean\"], 0.5))\n",
    "assert(np.isclose(ret_dict[\"SD\"], 0.319, atol=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>stats_channel</pre></strong> passed! ðŸŒŸ</p>"
      ],
      "text/plain": [
       "stats_channel results: All test cases passed!"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"stats_channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Now do the second half - \n",
    "\n",
    "This function calculates the stats for an entire channel of the data, and stores the result in a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stats_for_channel(data, n_dims):\n",
    "    \"\"\" Calculate the stats for a channel\n",
    "    @param data - an n_timestamps * n_dims size array\n",
    "    @param n_dims - 1, 2, or 3 (just x; x,y; or x,y,z)\n",
    "    @return A list of dictionaries. The list is the length of n_dims\"\"\"\n",
    "\n",
    "    stats_list = []\n",
    "    # TODO Copy in your for loop from the statistics problem in Lab 1\n",
    "    # - You DO need to slice the data into the x,y,z channels\n",
    "    # - You need to loop n_dims times\n",
    "    # - Don't forget to return the array\n",
    "    data_stats = []\n",
    "    for r in range(n_dims):\n",
    "        slice_all = data[:, r::n_dims]\n",
    "        dict_all = {\"Min\" : np.min(slice_all),\n",
    "                    \"Max\" : np.max(slice_all),\n",
    "                    \"Mean\": np.mean(slice_all),\n",
    "                    \"SD\": np.std(slice_all)}\n",
    "        data_stats.append(dict_all)\n",
    "\n",
    "    return data_stats\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# If you're having trouble, try setting n_dims to 1 and use test_data for the data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing with known data - make a fake data set with 5 time steps and x, y, z data\n",
    "#  \n",
    "test_stats = np.zeros((5, 3))\n",
    "# Set the x data to be ones\n",
    "test_stats[:, 0] = np.ones(5)\n",
    "# Set the y data to be twos\n",
    "test_stats[:, 1] = np.ones(5) * 2\n",
    "# Set the z data to be threes\n",
    "test_stats[:, 2] = np.ones(5) * 3\n",
    "\n",
    "# Now get the actual stats\n",
    "ret_stats_array = calc_stats_for_channel(test_stats, n_dims=3)\n",
    "\n",
    "# Check the mean result for x, y, and z - should be 1, 2, and 3 respectively\n",
    "assert(ret_stats_array[0][\"Mean\"] == 1.0)\n",
    "assert(ret_stats_array[1][\"Mean\"] == 2.0)\n",
    "assert(ret_stats_array[2][\"Mean\"] == 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this should work\n",
    "ret_stats_rh_accelerometer = calc_stats_for_channel(rh_accelerometer_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# As should this\n",
    "res_stats_lh_gyroscope = calc_stats_for_channel(lh_gyroscope_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>loop_data_calc_stats</pre></strong> passed! ðŸŒŸ</p>"
      ],
      "text/plain": [
       "loop_data_calc_stats results: All test cases passed!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"loop_data_calc_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Boolean slicing to get successful versus unsuccessful statistics out\n",
    "\n",
    "Use the functions you just wrote to get out the min and max z values for each type of hand motion.\n",
    "\n",
    "For this problem I have written code that is *incorrect*. You know the functions themselves are correct - you just tested them. The following bits of code have something wrong with either the way the function is called OR with the way the results are gotten back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clap: Minimum -1.04 and maximum 9.06 value of right hand accelerometer z channel\n",
      "Snap: Minimum -2.77 and maximum 1.05 value of right hand accelerometer z channel\n",
      "High five: Minimum -0.74 and maximum -0.32 value of right hand accelerometer z channel\n"
     ]
    }
   ],
   "source": [
    "# Boolean filters for getting rows for a specific motion type. \n",
    "# Motion type should be the last row in all_data.\n",
    "motion_type = all_data[:, -1]\n",
    "\n",
    "# These should match the specific IDs for each motion type.\n",
    "b_clap = motion_type == 1\n",
    "b_snap = motion_type == 3\n",
    "b_high_five = motion_type == 2\n",
    "\n",
    "# Use b_clap to pick out the rows that are for claps. Send all column data for the selected rows.\n",
    "#   Right hand accelerometer has 3 dimensions (x,y,z)\n",
    "#   There's two errors here - one that actually will create incorrect results, one that just *happens* to work\n",
    "#   correctly, although it doesn't do what the first sentance says...\n",
    "\n",
    "ret_rh_accelerometer_clap = calc_stats_for_channel(rh_accelerometer_data[b_clap], n_dims=3)\n",
    "\n",
    "# The minimum should be in the third (last) element in the list, the \"min\" key\n",
    "z_min_clap = ret_rh_accelerometer_clap[2][\"Min\"]\n",
    "z_max_clap = ret_rh_accelerometer_clap[2][\"Max\"]\n",
    "\n",
    "# Now, do the same thing above, but for snap and high_five\n",
    "\n",
    "ret_rh_accelerometer_clap = calc_stats_for_channel(rh_accelerometer_data[b_snap], n_dims=3)\n",
    "z_min_snap = ret_rh_accelerometer_clap[2][\"Min\"]\n",
    "z_max_snap = ret_rh_accelerometer_clap[2][\"Max\"]\n",
    "\n",
    "ret_rh_accelerometer_clap = calc_stats_for_channel(rh_accelerometer_data[b_high_five], n_dims=3)\n",
    "z_min_high_five = ret_rh_accelerometer_clap[2][\"Min\"]\n",
    "z_max_high_five = ret_rh_accelerometer_clap[2][\"Max\"]\n",
    "\n",
    "print(f\"Clap: Minimum {z_min_clap} and maximum {z_max_clap} value of right hand accelerometer z channel\")\n",
    "print(f\"Snap: Minimum {z_min_snap} and maximum {z_max_snap} value of right hand accelerometer z channel\")\n",
    "print(f\"High five: Minimum {z_min_high_five} and maximum {z_max_high_five} value of right hand accelerometer z channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>boolean_slicing</pre></strong> passed! ðŸŒˆ</p>"
      ],
      "text/plain": [
       "boolean_slicing results: All test cases passed!"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Optional/Extra credit: print out all of the rows where the minimum z value for a clap motion was reached\n",
    "\n",
    "See the tutorial on **np.where** (c_tutorial_where.ipynb)\n",
    "\n",
    "TODO: Use **np.where** to pick out the row that has the minimum z value for a clap motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 48, Time step: 77331.0\n"
     ]
    }
   ],
   "source": [
    "# Use np.where to get out the indices. You can use == OR np.isclose() here; either works. In general, use .isclose for \n",
    "#  floating point comparisons.\n",
    "# Append the row number of any matches to this list\n",
    "all_rows_with_min = []\n",
    "\n",
    "# Look at JUST the z values in rh_accelerometer_data\n",
    "all_indices_from_where = np.where(np.isclose(rh_accelerometer_data[b_clap, 2], z_min_clap))\n",
    "\n",
    "# Pseudo code - see tutorial for exact format\n",
    "# for all row in all_indices_from_where\n",
    "#    if this is row is from a clap: \n",
    "#       print(f\"Row: {r}, Time step: {c}\")\n",
    "\n",
    "for r in all_indices_from_where[0]:\n",
    "    all_rows_with_min.append(r)\n",
    "    timestep = all_data[r, 0]\n",
    "    print(f\"Row: {r}, Time step: {timestep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>optional_where</pre></strong> passed! ðŸš€</p>"
      ],
      "text/plain": [
       "optional_where results: All test cases passed!"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"optional_where\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"N/A\"}\n",
    "# List of URLS I25 (creates a set)\n",
    "websites = {\"N/A\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>hours_collaborators</pre></strong> passed! ðŸŒŸ</p>"
      ],
      "text/plain": [
       "hours_collaborators results: All test cases passed!"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit\n",
    "\n",
    "- Do a restart then run all to make sure everything runs ok\n",
    "- Save the file\n",
    "- Submit just this .ipynb file through gradescope, Lab 2, functions\n",
    "- You do NOT need to submit the data files - we will supply those\n",
    "- Where there are given variable/file names (eg, foo = ...) DON'T change those, or the autograder will fail\n",
    "\n",
    "If the Gradescope autograder fails, please check here first for common reasons for it to fail\n",
    "    https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing\n",
    "\n",
    "Most likely failure for this assignment is not naming the data directory and files correctly; capitalization matters for the Gradescope grader. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(z_min_clap, -1.04)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_max_clap, 9.06)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_min_snap, -2.77)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_max_snap, 1.05)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_min_high_five, -0.74)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(z_max_high_five, -0.32)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "check_slice": {
     "name": "check_slice",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert rh_accelerometer_data.shape == (285, 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[0, 0], 0.7)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[0, -1], -0.41)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[-1, 0], 0.07)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(rh_accelerometer_data[-1, -1], -0.98)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert lh_gyroscope_data.shape == (all_data.shape[0], 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(lh_gyroscope_data[0, 0], 429.34)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(lh_gyroscope_data[-1, -1], -154.36)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "get_data": {
     "name": "get_data",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert get_file_info('Data/S10F10.csv') == {'csv_path': 'Data/S10F10.csv', 'motion_id': high_five_id}\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_file_info('Data/S07S05.csv') == {'csv_path': 'Data/S07S05.csv', 'motion_id': snap_id}\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert get_file_info('Data/S03C09.csv') == {'csv_path': 'Data/S03C09.csv', 'motion_id': clap_id}\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(np.mean(all_data[:, 0]), 56082.1684, atol=0.001)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(np.mean(all_data[:, -1]), 1.95789, atol=0.001)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert not 'not filled out' in worked_with_names\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert not 'not filled out' in websites\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert hours > 0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "loop_data_calc_stats": {
     "name": "loop_data_calc_stats",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert len(ret_stats_array) == 3\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ret_stats_array[0]['Mean'] == 1.0\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ret_stats_array[1]['Mean'] == 2.0\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert ret_stats_array[2]['Mean'] == 3.0\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "optional_where": {
     "name": "optional_where",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert all_rows_with_min == [48]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "stats_channel": {
     "name": "stats_channel",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(ret_dict['Min'], 0.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(ret_dict['Max'], 1.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(ret_dict['Mean'], 0.5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(ret_dict['SD'], 0.319, atol=0.01)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
